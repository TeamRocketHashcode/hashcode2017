{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import knapsack as ks\n",
    "\n",
    "id_file_out = 0\n",
    "files_ext = {0:'.in', 1:'.out'}\n",
    "files = {0:'me_at_the_zoo', 1:'videos_worth_spreading', 2:'trending_today', 3:'kittens'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***************** Loading *****************\n",
      "File description \t {'n_cache': 10, 'n_endpoint': 10, 'size_cache': 100, 'n_video': 100, 'requ_des': 100}\n",
      "Videos sizes \t\tshape= (100,) , nnz= 100\n",
      "Endpoint to chache \tshape= (10, 10) , nnz= 32\n",
      "Endpoint to video \tshape= (10, 100) , max= 3296.0\n"
     ]
    }
   ],
   "source": [
    "def load_data(id_file_to_load = 0, print_debug = True):\n",
    "    print('\\n***************** Loading *****************')\n",
    "    # Load file\n",
    "    file = open(files[id_file_to_load] + files_ext[0], 'r') \n",
    "\n",
    "    # Header / Video / Endpoints / request descr. / Cache\n",
    "    header = file.readline().replace('\\n','')\n",
    "    header = np.fromstring(header, dtype=int, sep=' ')\n",
    "    header_dict = {   'n_video':header[0], 'n_endpoint':header[1], \n",
    "                      'requ_des':header[2], 'n_cache':header[3],\n",
    "                      'size_cache':header[4]}\n",
    "\n",
    "    # Video size in MB\n",
    "    video_size = file.readline().replace('\\n','')\n",
    "    video_size = np.fromstring(video_size, dtype=int, sep=' ')\n",
    "\n",
    "    # Endpoints locations and connections\n",
    "    endpoint_cache = np.zeros((header_dict['n_endpoint'], header_dict['n_cache'])) # Latency endpoint to cache\n",
    "    endpoint_datacenter = np.zeros(header_dict['n_endpoint']) # Latency endpoint to datacenter\n",
    "    endpoint_video = np.zeros((header_dict['n_endpoint'], header_dict['n_video'])) # Endpoints requests\n",
    "\n",
    "    # Reding endpoint to cache latency and endpoint to data_center latency\n",
    "    for id_endpoint in range(header_dict['n_endpoint']):\n",
    "        endpoint = file.readline().replace('\\n','').split(' ')\n",
    "        endpoint_datacenter[id_endpoint] = int(endpoint[0])\n",
    "        n_latency = int(endpoint[1])\n",
    "        for i in range(n_latency):\n",
    "            lat_cache = file.readline().replace('\\n','').split(' ')\n",
    "            endpoint_cache[id_endpoint, int(lat_cache[0])] = int(lat_cache[1])\n",
    "\n",
    "    for id_requ_des in range(header_dict['requ_des']):\n",
    "        requ_des = file.readline().replace('\\n','').split(' ')\n",
    "        endpoint_video[int(requ_des[1]), int(requ_des[0])] += int(requ_des[2])\n",
    "    file.close()\n",
    "    \n",
    "    if print_debug:\n",
    "        print('File description', '\\t', header_dict)\n",
    "        print('Videos sizes', '\\t\\tshape=', video_size.shape, ', nnz=', len(np.nonzero(video_size)[0]))\n",
    "        print('Endpoint to chache', '\\tshape=', endpoint_cache.shape, ', nnz=', len(np.nonzero(endpoint_cache)[0]))\n",
    "        print('Endpoint to video', '\\tshape=', endpoint_video.shape, ', max=', np.max(endpoint_video))\n",
    "    \n",
    "    return endpoint_cache, endpoint_datacenter, endpoint_video, video_size, header_dict[\"size_cache\"]\n",
    "\n",
    "\n",
    "\n",
    "def save_file(id_file_to_save = 0, caches_video_lists=None):\n",
    "    print('\\n***************** Saving *****************')\n",
    "    filename = files[id_file_to_save] + files_ext[1]\n",
    "    # Delete if existing\n",
    "    if os.path.isfile(filename):\n",
    "        os.remove(filename)\n",
    "    file = open(filename, 'a') \n",
    "    \n",
    "    # Write number caches\n",
    "    file.write(str(len(caches_video_lists)) + '\\n')\n",
    "\n",
    "    # Write each cache\n",
    "    for i, caches in enumerate(caches_video_lists):\n",
    "        # Print chache id\n",
    "        file.write(str(i) + ' ')\n",
    "        for j, video in enumerate(caches):\n",
    "            # Print video ids\n",
    "            file.write(str(video))\n",
    "            # Print space only if not last item\n",
    "            if j != len(caches)-1:\n",
    "                file.write(' ')\n",
    "        file.write('\\n')\n",
    "    file.close()\n",
    "    # Out save file\n",
    "    print('... saved as \\\"' + filename + '\\\"')\n",
    "\n",
    "# Load data\n",
    "endpoint_cache, endpoint_datacenter, endpoint_video, video_size, size_cache  = load_data(id_file_to_load=id_file_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cache_videos_saved = np.zeros((endpoint_cache.shape[1], video_size.shape[0])) # Latency endpoint to cache\n",
    "cache_videos_saved.shape\n",
    "\n",
    "for i in range(endpoint_cache.shape[1]):\n",
    "    for j in range(endpoint_cache.shape[0]):\n",
    "        if endpoint_cache[j][i] > 0:\n",
    "            for k in range(video_size.shape[0]):\n",
    "                if(endpoint_video[j][k] > 0):\n",
    "                    # print(\"saved time on video\", k, \"with cache\", i, \"with endpoint\", j)\n",
    "                    pass\n",
    "                cache_videos_saved[i][k] += (endpoint_datacenter[j] - endpoint_cache[j][i]) * endpoint_video[j][k]\n",
    "\n",
    "# Get feature for all caches\n",
    "res_tot = []\n",
    "for i in range(cache_videos_saved.shape[0]):\n",
    "    videos = []\n",
    "    # Get items\n",
    "    items_value = cache_videos_saved[i].astype(int)\n",
    "    items_weight = video_size\n",
    "    items = list(zip(items_weight,items_value))\n",
    "    # Solve it\n",
    "    solution, w, v, ids_vid = ks.solve(items, size_cache)\n",
    "    res_tot.append(ids_vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***************** Saving *****************\n",
      "... saved as \"me_at_the_zoo.out\"\n"
     ]
    }
   ],
   "source": [
    "# Save data\n",
    "save_file(id_file_to_save=id_file_out, caches_video_lists=res_tot)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
